{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Chapter 3: Learning Languages\n",
    "\n",
    "This notebook provides the code written for and used in the Chapter 3 of my dissertation **_SigmaPie_ for subregular and subsequential grammar induction**. All the links will be added soon. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators and evaluators: the setup for the experiments\n",
    "\n",
    "## Step 1: loading dependencies, including _SigmaPie_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from random import choice, randint\n",
    "from pprint import pprint\n",
    "\n",
    "# #I'm also adding some more to make things easier\n",
    "import pickle\n",
    "def write_report(this, which):\n",
    "    if which == \"data\":\n",
    "        pickle.dump(globals()[this].data, open(\"results_/\" + this + \"/data\", \"wb\"))\n",
    "    elif which == \"sample\":\n",
    "        pickle.dump(globals()[this+\"_sample\"], open(\"results_/\" + this + \"/sample\", \"wb\"))\n",
    "    elif which == \"grammar\":\n",
    "        pickle.dump(globals()[this], open(\"results_/\" + this + \"/grammar\", \"wb\"))\n",
    "    print(\"recorded\", which)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\C\\2022Summer\\SigmaPie\\src\n",
      "\n",
      "You successfully loaded SigmaPie. \n",
      "\n",
      "Formal language classes and grammars available:\n",
      "\t* strictly piecewise: SP(alphabet, grammar, k, data, polar);\n",
      "\t* strictly local: SL(alphabet, grammar, k, data, edges, polar);\n",
      "\t* tier-based strictly local: TSL(alphabet, grammar, k, data, edges, polar, tier);\n",
      "\t* multiple tier-based strictly local: MTSL(alphabet, grammar, k, data, edges, polar).\n",
      "\n",
      "Alternatively, you can initialize a transducer: FST(states, sigma, gamma, initial, transitions, stout).\n",
      "Learning algorithm:\n",
      "\tOSTIA: ostia(sample, sigma, gamma).\n",
      "c:\\C\\2022Summer\\subregular-experiments\n"
     ]
    }
   ],
   "source": [
    "# accessing SigmaPie toolkit: I know, horrible!\n",
    "# I promise I'll make it a package soon\n",
    "'''%cd local_sigmapie/code/\n",
    "from main import *\n",
    "%cd ../..'''\n",
    "%cd ../SigmaPie/src\n",
    "from sigmapie import *\n",
    "%cd ../../subregular-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backness_harmony(string):\n",
    "    \"\"\"\n",
    "    Tells if a string is well-formed according to rules\n",
    "    of Turkish backness harmony.\n",
    "    \"\"\"\n",
    "    front_class, back_class = \"Iaou\", \"ieOU\"\n",
    "    front, back = False, False\n",
    "    \n",
    "    for v in front_class + back_class:\n",
    "        if v in string:\n",
    "            front = True if v in front_class else front\n",
    "            back = True if v in back_class else back\n",
    "\n",
    "    return not (front and back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding_harmony(string):\n",
    "    \"\"\"\n",
    "    Tells if a string is well-formed according to rules\n",
    "    of Turkish rounding harmony.\n",
    "    \"\"\"\n",
    "    high, low, rounded = \"iIuU\", \"aeoO\", \"uUoO\"\n",
    "    \n",
    "    vowels = \"\".join([v for v in string if v in high + low])\n",
    "    if len(vowels) < 2:\n",
    "        return True\n",
    "    \n",
    "    ro = vowels[0] in rounded\n",
    "    \n",
    "    for v in vowels[1:]:\n",
    "        if v in low:\n",
    "            if v in rounded:\n",
    "                return False\n",
    "            ro = False\n",
    "        elif (ro and v not in rounded) or (not ro and v in rounded):\n",
    "            return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backness_and_rounding(string):\n",
    "    return backness_harmony(string) and rounding_harmony(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turkish_word(length = 10, cons = \"x\", vowel_cluster = (1, 2),\n",
    "                          cons_cluster = (0, 3)):\n",
    "    \"\"\"\n",
    "    This generator generates fake Turkish words: namely, the words in which\n",
    "    the harmonic system and rules of Turkish are preserved, but all consonants\n",
    "    were substituted by a single given consonant.\n",
    "    \n",
    "    Arguments:\n",
    "    * length (int): a length of a word that needs to be generated;\n",
    "    * cons (str): a single character (or an empty string if only vowels\n",
    "                  need to be generated), a \"choice\" of the consonant \n",
    "                  that makes this harmony long-distant;\n",
    "    * vowel_cluster (tuple[int, int]): a tuple of integers representing\n",
    "                                       minimal and maximal length of\n",
    "                                       the vowel cluster;\n",
    "    * cons_cluster (tuple[int, int]): a tuple of integers representing\n",
    "                                      minimal and maximal length of\n",
    "                                      the consonantal cluster.\n",
    "                                      \n",
    "    Returns:\n",
    "    * str: a fake Turkish harmonic word, where all consonants are masked.\n",
    "    \"\"\"\n",
    "    if length < 1:\n",
    "        raise ValueError(\"Words cannot be so short.\")\n",
    "    \n",
    "    vowels = {\n",
    "        (True, True, True):\"u\",\n",
    "        (True, True, False):\"I\",\n",
    "        (True, False, True):\"o\",\n",
    "        (True, False, False):\"a\",\n",
    "        (False, True, True):\"U\",\n",
    "        (False, True, False):\"i\",\n",
    "        (False, False, True):\"O\",\n",
    "        (False, False, False):\"e\"\n",
    "    }\n",
    "    \n",
    "    backness = choice([True, False])\n",
    "    height = choice([True, False])\n",
    "    rounding = choice([True, False])\n",
    "    \n",
    "    specs = (backness, height, rounding)\n",
    "    word = \"\"\n",
    "    \n",
    "    if choice([0, 1]):\n",
    "            word += \"x\" * randint(*cons_cluster)\n",
    "            \n",
    "    while len(word) < length:\n",
    "        vc = vowels[specs] * randint(*vowel_cluster)\n",
    "        \n",
    "        # this part is neededd to avoid the word-initial *oo clusters\n",
    "        '''if len(vc) > 1 and not height and rounding:\n",
    "            rounding = False\n",
    "            vc = vc[0] + vowels[(backness, height, rounding)] * (len(vc) - 1)\n",
    "         '''   # # #temporary\n",
    "        word += vc\n",
    "        word += \"x\" * randint(*cons_cluster)\n",
    "        \n",
    "        height = choice([True, False])\n",
    "        rounding = False if not height else rounding\n",
    "        specs = (backness, height, rounding)\n",
    "        \n",
    "    return word[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_turkish_words(n = 10, length = 10, cons = \"x\",\n",
    "                           vowel_cluster = (1, 2), cons_cluster = (1, 3)):\n",
    "    \"\"\"\n",
    "    This generator generates a list of fake Turkish words.\n",
    "    \n",
    "    Arguments:\n",
    "    * n (int): a number of strings that need to be generated;\n",
    "    ... for the rest of the arguments, see generate_turkish_word.\n",
    "    \n",
    "    Outputs:\n",
    "    * list: the list containing n fake Turkish words.\n",
    "    \"\"\"\n",
    "    return [turkish_word(length, cons, vowel_cluster, cons_cluster) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_evaluator(data, rule):\n",
    "    \"\"\"\n",
    "    Evaluates the provided data with respect to a given\n",
    "    rule of harmony.\n",
    "    \n",
    "    Arguments:\n",
    "    * data (list[str]): a list of strings tht need to be evaluated;\n",
    "    * rule (function): a function that evaluates a string according\n",
    "                       to some harmony.\n",
    "                       \n",
    "    Results:\n",
    "    * Prints the report that shows if the data follows the rule.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    bad = list()\n",
    "    for w in progressBar(data, prefix = \"evaluating\"):# #\n",
    "        # # #correct = (correct + 1) if rule(w) else correct# # #I changed it\n",
    "        if rule(w):\n",
    "            correct += 1\n",
    "        else:\n",
    "            bad.append(w)\n",
    "        \n",
    "    ratio = (correct / len(data))\n",
    "    print(f\"Percentage of harmonic words: {int(ratio * 100)}%.\")\n",
    "    if len(bad) > 0:\n",
    "        print(\"illegal words:\", bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created grammar object\n",
      "populated data\n",
      "extracting alphabet |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "generating ngrams |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "extracting symbols |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "annotating input, attesting k-grams |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "calculating paths |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "learning unattested grams |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "gathering grammars |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "recorded grammar\n",
      "generating items |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "recorded sample\n",
      "evaluating |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "Percentage of harmonic words: 99%.\n",
      "illegal words: ['Uxxxi', 'oxxxIa', 'xUxxxiixxeiiix']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(\"--------------------------\")\\nprint(\"Generates such strings:\", globals()[this+\"_sample\"][:15])\\nprint(\"--------------------------\")\\nprint(\"Size of the grammar:\", len(globals()[this].grammar))\\nprint(\"--------------------------\")\\nprint(\"Grammars:\", globals()[this].grammar)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this = \"mitsl9\"\n",
    "globals()[this] = MITSL(polar = \"n\")\n",
    "print(\"created grammar object\")\n",
    "# #globals()[this].data = toy_mhwb\n",
    "globals()[this].data = pickle.load(open(\"results_/\" + this + \"/data\", \"rb\"))\n",
    "#write_report(this, \"data\")\n",
    "globals()[this].data.append(\"\") # added to eliminate *>< on all tiers\n",
    "print(\"populated data\")\n",
    "globals()[this].extract_alphabet()\n",
    "globals()[this].learn()\n",
    "write_report(this, \"grammar\")\n",
    "\n",
    "globals()[this+\"_sample\"] = globals()[this].generate_sample(n = 1000)\n",
    "write_report(this, \"sample\")\n",
    "harmonic_evaluator(globals()[this+\"_sample\"], backness_and_rounding)\n",
    "'''print(\"--------------------------\")\n",
    "print(\"Generates such strings:\", globals()[this+\"_sample\"][:15])\n",
    "print(\"--------------------------\")\n",
    "print(\"Size of the grammar:\", len(globals()[this].grammar))\n",
    "print(\"--------------------------\")\n",
    "print(\"Grammars:\", globals()[this].grammar)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "Percentage of harmonic words: 99%.\n",
      "illegal words: ['Uxxi', 'Uxxii', 'Uxxiix', 'uxxuxuxxI', 'Uxxi']\n"
     ]
    }
   ],
   "source": [
    "harmonic_evaluator(globals()[this+\"_sample\"], backness_and_rounding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting alphabet |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "generating ngrams |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "extracting symbols |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "annotating input, attesting k-grams |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "calculating paths |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "learning unattested grams |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "gathering grammars |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "generating items |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "evaluating |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "Percentage of harmonic words: 100%.\n"
     ]
    }
   ],
   "source": [
    "d = generate_turkish_words(n=15000,cons_cluster=(1,4))\n",
    "g=MITSL(polar='n')\n",
    "g.data = d\n",
    "g.extract_alphabet()\n",
    "g.learn()\n",
    "s = g.generate_sample()# # #I made a mistake here by not specifiying n=1000, so see the next cell\n",
    "harmonic_evaluator(s, backness_and_rounding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating items |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "evaluating |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "Percentage of harmonic words: 95%.\n",
      "illegal words: ['oxxIxa', 'Oxxi', 'Oxxi', 'UxUxxixi', 'oxxxI', 'Oxxi', 'uxxI', 'Uxxxi', 'Oxxixe', 'Oxxixi', 'uxuxxIxxI', 'Uxxixi', 'uxxIx', 'Uxxi', 'Uxxi', 'uxxI', 'oxxxIxxIxxaxa', 'Oxxixixxixexixx', 'oxxIxIxaxx', 'Uxxixe', 'Oxxi', 'oxxxxIx', 'Oxxxix', 'oxxxIxI', 'uxxIxaxx', 'oxxI', 'Uxxxixxxe', 'Uxxi', 'oxxI', 'Uxxixi', 'Uxxxixixexxix', 'UxUxxxixxxi', 'Uxxxxxxixe', 'uxxI', 'Oxxix', 'oxxxIx', 'UxUxUxxi', 'oxuxxI', 'Oxxix', 'oxuxxIx', 'uxxI', 'uxxI', 'oxxIx', 'oxxxIxI']\n"
     ]
    }
   ],
   "source": [
    "s = g.generate_sample(n = 1000)\n",
    "harmonic_evaluator(s, backness_and_rounding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pickle.load(open(\"results_/mitsl9/grammar\", \"rb\"))\n",
    "mm = [i for i in progressBar(m.data) if not m.scan(i)]\n",
    "mm"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6213e0af081d56db034f795ff49d96980936e2ae540dda57fc6c3cbea6a5fc9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
